{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float)\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.0083e+00,  2.1826e+00,  3.7949e+00,  1.6405e+00,  7.3945e+00,\n",
       "        -3.8289e+00,  5.6582e+00,  3.4438e+00, -1.2711e+00,  1.4977e+00,\n",
       "         3.4136e+00,  1.1064e+01, -4.1898e+00,  9.4177e+00,  7.3382e+00,\n",
       "         6.0341e+00, -3.9672e+00,  2.4900e+00,  2.4337e+00,  4.7499e+00,\n",
       "         5.0379e-01,  2.8388e+00,  9.5111e+00,  7.5850e+00,  1.0175e-02,\n",
       "         4.2696e+00,  7.7069e+00, -3.4112e+00,  4.9983e+00,  1.9086e+00,\n",
       "         6.1196e+00,  4.8155e+00,  1.0141e+01,  8.5025e+00,  4.4841e+00,\n",
       "         4.0594e+00,  9.6775e+00,  1.2367e+00,  5.2889e-01,  2.7239e+00,\n",
       "        -2.2892e-04,  7.6300e+00, -3.2988e+00,  5.0428e+00,  1.0533e+01,\n",
       "         1.7923e+00,  6.1839e+00, -2.5238e+00, -1.5962e+00,  3.4050e+00,\n",
       "        -1.2568e-01,  3.8488e+00,  3.2912e+00, -3.5430e+00,  2.7817e+00,\n",
       "         5.8749e+00,  5.4281e+00,  7.8628e+00, -2.7953e+00,  2.9046e+00,\n",
       "         7.9227e+00,  6.0734e+00,  6.2562e+00,  3.9626e+00,  9.8252e-01,\n",
       "         8.2179e+00,  8.4450e+00,  4.0974e+00,  8.4830e+00,  6.9136e+00,\n",
       "         3.9881e+00,  2.9507e+00,  1.0522e+01,  5.5975e+00,  3.3736e+00,\n",
       "         7.2568e+00,  5.1738e+00,  8.6132e-01,  7.5848e+00,  7.5264e+00,\n",
       "         1.2200e+00,  4.1683e+00,  4.6520e+00,  1.0401e+01,  4.7521e+00,\n",
       "         4.8313e+00, -1.4931e+00,  5.1730e-01,  4.6256e+00, -4.0682e-01,\n",
       "         5.8596e+00,  6.1496e+00,  1.3436e+01,  6.5556e+00,  3.2314e+00,\n",
       "         1.0870e+01,  4.3429e+00, -8.1365e-01,  1.6275e+00,  1.3026e+00,\n",
       "         2.4312e+00,  8.4858e-01,  1.2582e+00,  6.3405e+00,  2.7914e+00,\n",
       "         1.8598e-02,  7.7577e+00,  5.5669e+00,  1.8210e+00,  4.6325e+00,\n",
       "         4.7721e+00,  3.7053e+00,  8.7799e+00,  5.8783e+00,  5.2968e+00,\n",
       "         1.5028e+00,  7.2763e+00,  6.0533e+00,  8.7543e+00,  6.7797e+00,\n",
       "         2.5367e+00,  2.9504e+00,  7.0199e+00,  1.5053e+00, -3.7743e+00,\n",
       "         5.6321e+00,  3.6848e-01,  7.9133e-01,  3.8062e+00,  3.3063e+00,\n",
       "         3.1545e+00,  3.4067e+00, -8.3128e-02,  1.8605e+00,  2.9343e+00,\n",
       "         8.6734e+00,  1.3980e+00,  6.5201e+00, -2.6428e+00,  1.0629e+00,\n",
       "         1.5525e+00,  3.0410e+00,  8.9797e+00,  8.7213e+00,  9.5050e+00,\n",
       "         6.7660e+00,  1.1308e+01,  5.1992e+00,  3.7131e+00,  8.8321e+00,\n",
       "         7.8242e+00,  4.7908e+00, -2.5273e+00,  3.8802e+00,  5.5291e+00,\n",
       "         2.1091e+00,  1.6479e+00,  1.6135e-01,  2.4411e+00,  1.1939e+01,\n",
       "        -6.8072e-02,  6.8557e+00,  7.8778e+00,  8.9134e+00,  2.0417e+00,\n",
       "        -1.7325e+00,  6.0224e+00,  6.3767e+00, -3.4624e-01,  8.7888e+00,\n",
       "         5.8292e+00,  6.2506e+00,  2.0827e+00,  8.8896e+00,  7.1320e+00,\n",
       "         5.8919e+00,  6.1246e+00, -8.3036e-02,  4.1222e+00,  5.8677e+00,\n",
       "         1.3924e+00,  4.6157e+00,  7.2704e+00,  4.0573e+00, -5.7293e-02,\n",
       "         1.1835e+00,  1.8042e-01,  7.1181e+00,  3.4358e-01,  4.1782e+00,\n",
       "         1.5812e+00,  2.2186e+00,  3.1969e+00,  8.3900e+00,  4.3959e+00,\n",
       "        -1.4016e+00,  6.1891e+00,  3.1239e+00,  2.9370e+00,  3.1891e+00,\n",
       "         3.4425e-01,  1.4515e+01,  7.0908e+00,  6.0151e+00,  1.7455e+00,\n",
       "         7.0907e+00,  3.5912e+00,  3.2201e+00,  9.3051e+00,  2.3098e+00,\n",
       "         5.8987e+00, -3.2373e-01,  2.7357e+00, -1.2169e+00,  2.8025e+00,\n",
       "         1.1229e+01,  1.1394e+01,  5.9236e-01,  5.8583e+00,  3.8548e+00,\n",
       "         5.2924e+00,  5.4106e+00,  5.6586e+00,  8.4995e-01,  3.9562e+00,\n",
       "         8.3987e+00,  9.0273e+00,  6.8401e+00,  5.1401e+00,  4.7768e+00,\n",
       "         7.0015e+00,  4.1731e-01,  1.3375e+01,  3.4058e+00,  4.8033e+00,\n",
       "         6.6939e+00,  5.2757e+00,  2.6041e+00,  1.2013e+00, -1.7608e+00,\n",
       "         7.7134e+00,  6.7205e+00,  2.1270e+00, -1.5143e-01,  1.4322e+00,\n",
       "         2.5236e+00,  5.1130e+00,  1.2387e+01, -1.5739e+00, -1.7964e+00,\n",
       "         8.1116e+00,  1.0275e+01,  5.3627e+00,  1.6690e+00,  7.8860e+00,\n",
       "         5.7072e+00,  7.2163e+00,  8.4303e-01,  3.9115e+00,  9.5639e+00,\n",
       "         1.2108e+00,  5.7060e+00,  5.3522e+00, -2.5432e+00,  3.7421e+00,\n",
       "         3.2937e+00,  1.8443e+00,  1.5413e+01,  6.2710e-01,  7.2392e+00,\n",
       "         1.0424e+01,  6.7540e+00,  1.7625e+00,  2.9055e+00,  1.0066e+01,\n",
       "         4.9885e+00,  3.6760e+00,  9.7950e+00,  6.2719e+00, -9.0257e-01,\n",
       "         4.0854e+00,  3.1625e+00,  5.3663e+00, -5.3541e+00,  3.5082e+00,\n",
       "        -6.0410e+00,  1.7010e+00, -7.7862e-01,  3.1661e+00,  4.3885e+00,\n",
       "         6.7525e+00,  6.5729e+00,  2.5366e+00,  7.5497e+00,  3.1461e+00,\n",
       "         4.0260e+00,  2.8919e+00, -2.7289e+00,  9.9954e-01,  1.7408e+00,\n",
       "         1.0304e+01,  7.7950e+00,  6.6421e+00,  7.6041e-01, -6.5922e+00,\n",
       "         4.5346e+00,  5.7464e+00,  2.5993e+00,  9.1080e+00,  5.0832e+00,\n",
       "         9.5109e+00,  5.7918e+00,  5.9271e+00,  6.0094e+00,  4.1409e+00,\n",
       "         8.9070e+00,  5.1728e+00,  5.6214e+00, -2.6473e+00,  2.4853e+00,\n",
       "         5.2888e+00,  2.9922e+00,  5.6943e+00,  8.4186e-01,  7.6161e+00,\n",
       "         3.3456e+00, -2.3093e+00,  2.3602e+00,  4.5442e-01,  3.7336e+00,\n",
       "         7.6526e+00,  6.0107e+00, -3.3858e+00,  2.5858e+00,  1.1338e+01,\n",
       "         2.7290e+00,  7.5296e+00,  7.4113e+00,  8.0561e+00,  1.4789e+00,\n",
       "         1.7460e+00,  2.3522e+00,  2.4588e+00,  7.5182e+00,  2.9815e+00,\n",
       "         8.7384e-01,  1.0700e+01, -4.9482e+00, -1.1155e+00,  5.2974e+00,\n",
       "         6.5074e+00,  3.8235e+00,  3.3342e+00,  1.0013e+01,  7.2112e+00,\n",
       "         1.0116e+01,  8.2235e-01, -1.2317e+00,  6.0577e+00,  1.7292e+00,\n",
       "         1.0420e+01,  4.1872e+00,  6.0215e+00,  4.5812e+00,  6.1135e+00,\n",
       "         1.0210e+00,  4.7096e-01,  1.4436e+00,  6.0137e+00,  1.8487e+00,\n",
       "         2.6278e+00, -3.9530e+00,  1.0182e+01, -3.0943e+00,  9.1173e+00,\n",
       "        -3.7192e+00,  1.7039e+00,  2.2081e-01,  2.3651e-01,  5.2039e+00,\n",
       "         6.0394e+00,  1.3630e+00,  7.1920e+00,  1.2514e+00,  4.3298e+00,\n",
       "         3.0389e+00,  2.0386e+00,  7.4368e+00,  1.0342e+01,  9.2285e+00,\n",
       "        -9.7395e-01, -1.8846e+00,  1.4101e+00,  6.4545e+00,  4.6536e+00,\n",
       "         7.9400e+00,  2.8709e+00,  4.2269e+00,  6.7217e+00,  8.6233e+00,\n",
       "        -3.2438e+00,  6.8008e+00, -5.4953e-01,  9.4073e+00,  9.4233e+00,\n",
       "         3.4246e+00,  4.8827e+00, -3.9740e+00,  1.4616e+00,  9.5662e+00,\n",
       "         5.4985e+00,  6.9439e+00,  4.7175e+00,  7.2781e+00,  2.1633e+00,\n",
       "         1.2431e+01,  6.3001e+00,  6.6785e+00, -2.0506e+00,  4.9000e+00,\n",
       "         9.4492e+00,  7.8954e+00,  3.1084e+00,  2.1946e+00,  1.3520e+00,\n",
       "         1.4535e+01,  6.7830e+00,  6.2069e+00,  6.4303e+00,  9.5642e+00,\n",
       "         1.4346e+01,  3.9952e+00,  3.7494e+00, -2.9397e+00,  6.7032e-01,\n",
       "         2.4233e-01, -5.2165e+00,  5.7739e+00,  1.8793e+00,  6.4383e+00,\n",
       "        -1.7464e+00,  2.3725e+00, -4.9177e-01,  7.2108e+00, -1.1913e+00,\n",
       "         5.4556e+00,  3.1327e+00,  3.2609e+00,  7.8055e+00,  4.6744e+00,\n",
       "         2.6411e+00,  4.4452e+00,  7.3011e+00,  8.5311e+00,  6.2199e-01,\n",
       "         2.5209e+00,  4.8098e+00,  4.7581e+00, -1.9415e+00,  1.4315e-01,\n",
       "         7.7293e+00,  9.3114e+00,  5.7694e+00,  5.6418e+00,  4.4469e+00,\n",
       "         3.2061e+00,  4.8894e+00,  5.2221e+00,  5.0966e+00,  5.6675e-01,\n",
       "         9.1924e+00,  6.1906e+00,  4.0289e+00,  3.3469e+00,  3.7061e+00,\n",
       "         5.0740e+00, -4.1008e-01,  5.9019e+00,  1.4360e+00, -9.1226e-01,\n",
       "         3.2556e+00, -1.2339e-01,  3.4929e+00, -9.9969e-02,  7.4302e+00,\n",
       "         5.4160e+00,  4.0662e+00, -1.3163e-01,  1.0102e+01,  2.6194e+00,\n",
       "         2.0221e+00,  7.4252e+00,  2.0832e+00,  5.4033e+00,  6.5358e+00,\n",
       "         7.0120e+00,  4.2115e-01,  9.6412e+00,  2.4706e+00,  2.9367e+00,\n",
       "        -5.4879e-01,  4.8900e+00,  5.5518e+00,  8.7783e+00, -5.5065e+00,\n",
       "         8.1324e+00,  5.6827e+00, -1.1927e+00,  1.1829e+01,  7.8178e+00,\n",
       "         1.5630e+00,  3.5978e+00,  6.3689e+00,  4.9462e-01,  1.1083e+00,\n",
       "         7.5571e+00,  6.7468e+00,  7.4872e+00,  7.7160e+00,  6.1312e+00,\n",
       "         1.3899e+01, -1.2006e+00,  2.7181e+00,  6.6166e+00,  5.5721e+00,\n",
       "        -3.1523e-01,  4.5870e+00,  9.7188e-01,  5.9106e+00,  8.2009e+00,\n",
       "         8.1044e+00,  7.1501e+00, -8.4250e-01,  5.9725e+00,  2.7840e+00,\n",
       "         3.7028e+00,  2.1466e+00,  5.8029e+00,  3.9556e+00,  5.9650e+00,\n",
       "         5.5085e+00,  6.5130e+00,  2.6226e+00,  2.1738e+00,  6.1751e-01,\n",
       "        -3.9600e+00,  1.8197e+00,  5.5573e+00,  4.1295e-01,  1.1389e+01,\n",
       "         7.9860e-01,  2.3771e+00,  2.7907e+00,  1.5000e+00,  2.0500e+00,\n",
       "        -8.0985e-01,  6.5483e+00,  9.0732e-01,  1.9186e+00,  7.2934e+00,\n",
       "         1.0434e+01,  9.4486e+00,  1.8098e+00,  5.1839e+00,  2.7670e+00,\n",
       "         2.5639e+00,  1.2996e+01,  1.8791e+00,  8.1979e+00,  9.0427e+00,\n",
       "         7.0234e+00,  4.6029e+00,  4.6968e+00, -4.4862e-01,  1.0483e+01,\n",
       "        -1.8010e+00,  1.9550e+00,  1.9890e+00,  3.4944e+00,  9.7726e+00,\n",
       "         1.8516e+00,  1.2181e+01,  4.8856e+00,  2.7169e+00,  5.4906e+00,\n",
       "         8.1971e-01,  2.8966e+00,  7.3845e+00,  8.1148e+00, -2.2735e+00,\n",
       "        -1.7081e-01,  8.0359e+00,  6.4785e+00,  1.9494e+00,  9.8791e+00,\n",
       "         7.8718e+00, -5.7633e-02,  5.0392e+00,  2.8135e+00,  7.4179e+00,\n",
       "         1.4731e-01,  7.5931e+00,  4.8418e+00,  1.0240e+01,  1.0566e+00,\n",
       "         4.6754e+00,  5.8166e+00,  3.0458e+00,  1.5471e-01,  5.8982e-01,\n",
       "         2.4819e+00,  4.9135e+00,  1.2840e+01,  5.5322e+00,  2.7031e+00,\n",
       "         3.4857e+00,  3.9726e+00,  8.5951e+00, -1.1194e-04,  5.2843e+00,\n",
       "         1.3830e+00,  5.6288e+00, -2.2564e+00,  2.9524e+00,  1.1862e+00,\n",
       "         6.0268e+00, -2.3322e+00, -7.2539e-01,  3.1095e+00,  2.5021e+00,\n",
       "         4.8099e+00,  4.0902e+00,  1.2056e+00,  4.7217e+00,  4.0739e-01,\n",
       "         6.1827e+00,  5.6954e+00,  8.2025e+00,  1.0801e+00,  7.1600e+00,\n",
       "         1.2426e+00,  3.4841e+00,  1.4225e+00,  2.0024e+00,  3.0854e+00,\n",
       "        -1.7572e+00,  1.0715e+01,  2.5916e+00, -8.4235e-01,  6.4462e+00,\n",
       "        -4.2372e+00,  2.2842e+00,  7.1864e+00,  4.2017e+00,  1.7415e+00,\n",
       "         3.7118e+00, -1.9474e+00,  3.9163e+00,  2.2599e+00,  4.8992e+00,\n",
       "         7.2081e-01,  2.1127e+00,  8.2068e+00,  8.5965e+00,  2.4115e+00,\n",
       "         8.4323e+00, -1.3985e+00,  5.0463e+00, -2.1242e+00,  6.9857e+00,\n",
       "        -1.4538e+00,  1.1083e+01,  2.4421e+00,  1.5271e-01,  1.0577e+01,\n",
       "         2.4253e+00,  6.5413e+00,  2.5586e+00, -9.1789e-01,  6.7221e+00,\n",
       "         5.4304e+00, -3.4780e+00,  6.2848e+00,  3.9798e+00,  4.1158e+00,\n",
       "         1.0708e+01,  9.2563e+00,  1.1055e+00,  5.9320e+00,  3.0002e+00,\n",
       "         2.2579e+00,  4.1643e+00,  1.1624e+01, -1.0166e+00,  2.2072e+00,\n",
       "         6.6912e+00,  9.1756e+00,  1.0441e+01,  7.2560e+00, -2.5636e+00,\n",
       "         3.1180e+00,  3.9457e+00,  8.9871e+00,  5.5025e+00, -5.8899e+00,\n",
       "         2.5383e+00,  1.9743e+00,  6.4276e+00,  3.4347e+00,  1.1028e+01,\n",
       "         4.8381e+00,  8.9134e+00,  8.3119e+00,  3.3586e+00,  2.8361e+00,\n",
       "         3.0416e+00,  3.2655e+00, -5.9517e-01,  5.0493e+00,  3.9773e+00,\n",
       "         7.7893e+00,  2.0021e+00,  7.4531e+00, -3.1451e+00,  1.2700e+01,\n",
       "         7.8732e+00,  1.2820e+00,  3.6297e+00,  6.1659e-01,  4.8842e+00,\n",
       "         1.2694e+01, -7.3078e+00, -5.2336e-01,  5.1685e+00,  7.7197e+00,\n",
       "         1.0425e+01,  6.5136e+00,  1.3524e+00,  3.3287e+00,  8.7778e+00,\n",
       "         7.4021e+00,  1.0948e+01,  7.4088e+00,  3.2374e+00,  1.1012e+01,\n",
       "         1.0693e+01, -3.2354e+00,  6.4010e+00,  5.4705e+00,  6.4878e+00,\n",
       "         3.2062e+00,  2.7248e-01,  5.6793e+00,  1.5241e-01,  3.3720e+00,\n",
       "        -4.4770e+00,  4.1850e+00,  5.6153e-01,  2.5984e+00, -6.2557e-01,\n",
       "         2.9526e+00, -1.5755e+00,  3.6475e+00,  1.7563e+01, -6.5658e+00,\n",
       "        -1.1800e+00,  3.3915e+00,  8.5793e+00,  1.6221e+00,  6.2729e+00,\n",
       "         1.6784e+00, -1.7949e+00,  4.2875e+00, -9.9721e-01,  5.5364e+00,\n",
       "         4.7316e+00,  2.4632e+00,  2.0359e+00,  7.4636e+00,  5.7275e+00,\n",
       "         3.5880e+00,  2.8317e+00,  3.2821e+00,  9.2681e+00,  1.2624e+00,\n",
       "         5.2824e-01,  9.1490e-01,  4.7807e+00,  8.2390e+00,  9.2241e+00,\n",
       "         9.3955e-01,  8.7496e+00,  5.6291e+00,  4.4579e+00,  1.6135e+00,\n",
       "         9.8856e+00,  4.3952e+00,  7.2196e+00, -6.5727e-01,  3.2182e+00,\n",
       "         4.6020e+00,  6.0110e+00,  5.3713e+00,  1.0437e-01,  7.6728e-01,\n",
       "         2.5610e+00,  2.1386e-01,  7.6268e+00,  4.4601e+00,  3.8994e-01,\n",
       "        -2.5914e+00,  2.1093e+00,  1.3184e+01,  6.2126e+00,  9.5737e+00,\n",
       "         8.5453e+00,  5.1137e+00,  5.7314e-01,  3.0985e+00,  1.0280e+01,\n",
       "         3.7495e+00,  1.2319e+00,  4.3329e+00,  7.0405e+00, -2.2249e+00,\n",
       "         4.7170e-01,  2.4307e+00,  1.5415e+00,  2.9405e+00,  8.2154e+00,\n",
       "         7.5804e+00,  5.1490e+00,  1.2361e+01,  1.0870e+01,  5.2745e+00,\n",
       "         1.5335e+00,  4.8663e+00,  4.6580e+00,  1.1706e+01,  8.5660e-01,\n",
       "        -4.4937e+00,  9.3108e-01,  3.7873e+00,  1.3898e+01,  9.6142e-01,\n",
       "         2.3554e+00,  1.3796e+00,  9.3980e+00,  6.9113e+00,  7.5561e+00,\n",
       "        -3.2265e+00,  7.2595e+00,  3.2311e+00,  1.0579e+01,  2.0804e+00,\n",
       "        -4.4699e-02,  3.7133e+00,  2.9959e+00,  3.9228e+00,  9.1815e+00,\n",
       "         1.0062e+01, -1.5289e+00,  2.4611e+00,  2.1927e-01,  1.3144e+00,\n",
       "         2.8592e+00,  7.3630e-01,  4.0091e+00,  6.0121e+00,  7.3854e+00,\n",
       "         6.2521e+00, -6.5076e-01,  6.6497e-01, -1.7694e+00,  5.1225e+00,\n",
       "         3.3008e+00,  7.7520e+00, -3.0245e+00,  4.6871e+00,  3.6071e+00,\n",
       "         6.6537e+00,  4.1607e+00,  5.7622e+00,  9.8039e-02,  8.5046e+00,\n",
       "         4.6331e+00,  1.0889e+01,  3.9262e-01,  6.8183e+00, -8.0306e-01,\n",
       "         4.0872e+00,  1.4871e+00,  5.6953e+00,  3.1579e+00,  5.2314e+00,\n",
       "         8.5196e+00,  7.0450e+00,  1.2451e+01,  9.1268e+00,  6.1228e+00,\n",
       "        -1.2854e+00,  3.7001e-01, -5.8193e-01,  8.4986e+00, -6.1662e-01,\n",
       "         2.1938e+00,  5.5242e+00,  3.0319e+00,  5.8040e+00,  2.0325e+00,\n",
       "         5.7156e+00,  4.0218e+00,  5.4034e+00,  7.6663e+00,  5.0470e+00,\n",
       "         3.3370e+00,  1.3509e+00,  2.1071e+00,  6.0784e+00,  8.5918e+00,\n",
       "        -1.6402e+00,  7.4833e+00, -1.3688e-01,  3.5483e+00,  1.1820e+01,\n",
       "         8.2913e+00, -6.8974e-01,  2.1804e+00, -2.2789e+00,  9.8721e+00,\n",
       "         7.6531e-01,  6.4859e+00,  4.3121e+00,  6.8886e+00,  4.1268e+00,\n",
       "         2.5018e+00,  1.7229e+00,  8.9600e+00,  2.0734e+00,  3.5176e+00,\n",
       "         3.5918e+00,  7.4203e+00,  4.6064e+00,  9.3017e+00,  3.2384e+00,\n",
       "         1.0848e+01,  1.0379e+01,  3.4513e+00,  8.1177e+00, -5.4405e+00,\n",
       "         2.0496e+00,  7.6381e+00,  7.5275e+00,  7.9017e+00,  7.0428e+00,\n",
       "         6.2336e+00,  3.2234e+00,  5.7563e+00,  5.5993e+00,  1.0610e+01,\n",
       "         3.4194e+00, -1.9779e-01, -2.0233e+00,  2.3761e+00, -3.1951e-01,\n",
       "         4.7266e+00,  5.5611e+00,  8.9897e+00,  3.2277e+00,  1.2949e+01,\n",
       "         8.4752e+00,  6.3573e+00,  2.2799e+00,  3.7810e+00, -2.3849e+00,\n",
       "         7.6811e+00,  6.1395e-01,  3.3603e+00,  2.8564e-01,  8.1590e+00,\n",
       "         8.8096e+00, -2.1471e+00,  6.3042e+00, -1.0419e+00,  1.2228e+01,\n",
       "         5.5640e+00,  1.0195e+00,  1.2323e+01,  3.5300e+00,  3.2533e-02,\n",
       "         9.9306e+00,  2.7648e+00,  6.0681e+00,  8.8211e-01, -7.3845e-01,\n",
       "         8.8726e+00,  1.7542e+00,  7.1526e+00,  6.7618e+00,  3.7377e+00])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "# 将训练数据的特征和标签组合\n",
    "dataset = Data.TensorDataset(features, labels)\n",
    "# 随机读取小批量\n",
    "data_iter = Data.DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1cb82700ac8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1079, -1.2713],\n",
      "        [ 0.6481, -0.7698],\n",
      "        [-0.2056,  0.0317],\n",
      "        [-0.4578,  0.0693],\n",
      "        [ 1.1537,  0.5432],\n",
      "        [-0.7874,  0.3113],\n",
      "        [-0.3952,  0.2095],\n",
      "        [ 0.9093,  0.8135],\n",
      "        [ 0.3539, -0.8804],\n",
      "        [-0.2139,  0.4963]]) tensor([8.3119, 8.1148, 3.6760, 3.0410, 4.6536, 1.5630, 2.7031, 3.2655, 7.9017,\n",
      "        2.0804])\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter:\n",
    "    print(X, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearNet(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = nn.Linear(n_feature, 1)\n",
    "    # forward 定义向前传播\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "net = LinearNet(num_inputs)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事实上我们还可以用nn.Sequential来更加方便地搭建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8ed7ae8abf56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# 写法三\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m net = Sequential(OrderedDict([\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m ]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# 写法一\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(num_inputs, 1)\n",
    ")\n",
    "\n",
    "# 写法二\n",
    "net = nn.Sequential()\n",
    "net.add_module('linear', nn.Linear(num_inputs, 1))\n",
    "\n",
    "# 写法三\n",
    "from collections import OrderedDict\n",
    "net = Sequential(OrderedDict([\n",
    "    ('linear', nn.Linear(num_inputs, 1))\n",
    "]))\n",
    "\n",
    "print(net)\n",
    "print(net[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3234, -0.3087]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.6707], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 这个参数是随机初始化的，后面会设置\n",
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "init.normal_(net.linear.weight, mean=0, std=0.01)\n",
    "init.constant_(net.linear.bias, val=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.03)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以为不同子网络设置不同的学习率，这在finetune时经常用到。例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =optim.SGD([\n",
    "                # 如果对某个参数不指定学习率，就使用最外层的默认学习率\n",
    "                {'params': net.subnet1.parameters()}, # lr=0.03\n",
    "                {'params': net.subnet2.parameters(), 'lr': 0.01}\n",
    "            ], lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调整学习率\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] *= 0.1 # 学习率为之前的0.1倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.000080\n",
      "epoch 2, loss: 0.000137\n",
      "epoch 3, loss: 0.000088\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        output = net(X)\n",
    "        l = loss(output, y.view(-1, 1))\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch %d, loss: %f' % (epoch, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3.4] Parameter containing:\n",
      "tensor([[ 2.0004, -3.4000]], requires_grad=True)\n",
      "4.2 Parameter containing:\n",
      "tensor([4.2000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "dense = net.linear\n",
    "print(true_w, dense.weight)\n",
    "print(true_b, dense.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "pyt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
